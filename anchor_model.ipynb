{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2fc0485a90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import tqdm\n",
    "import sklearn.metrics\n",
    "import math\n",
    "\n",
    "torch.manual_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "np.get_include() # do we need this on colab? \n",
    "cimport cython\n",
    "cimport numpy as np\n",
    "\n",
    "cdef dict bases={ 'A':<int>0, 'C':<int>1, 'G':<int>2, 'T':<int>3, 'N':<int>4, } \n",
    "\n",
    "@cython.boundscheck(False)\n",
    "def one_hot( str string ):\n",
    "    cdef np.ndarray[np.float32_t, ndim=2] res = np.zeros( (5,len(string)), dtype=np.float32 )\n",
    "    cdef int j\n",
    "    for j in range(len(string)):\n",
    "        if string[j] in bases: # bases can be 'N' signifying missing: this corresponds to all 0 in the encoding\n",
    "            res[ bases[ string[j] ], j ]=float(1.0)\n",
    "    return(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 19])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 4., 7., 0., 7.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np = one_hot(\"CCGCGNGGNGGCAGNNNNN\") #ACGTN\n",
    "x_tensor = torch.tensor(x_np)\n",
    "print(x_tensor.shape)\n",
    "torch.sum(x_tensor, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/'\n",
    "train_data = pd.read_csv(data_dir + 'anchor_datasets/anchor_master_train.csv')\n",
    "val_data = pd.read_csv(data_dir + 'anchor_datasets/anchor_master_val.csv')\n",
    "test_data = pd.read_csv(data_dir + 'anchor_datasets/anchor_master_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>anchor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22021</td>\n",
       "      <td>chr12</td>\n",
       "      <td>54686154</td>\n",
       "      <td>54690154</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9664</td>\n",
       "      <td>chr5</td>\n",
       "      <td>32470089</td>\n",
       "      <td>32474089</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11985</td>\n",
       "      <td>chr6</td>\n",
       "      <td>42035500</td>\n",
       "      <td>42039500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28325</td>\n",
       "      <td>chr17</td>\n",
       "      <td>62933100</td>\n",
       "      <td>62937100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1887</td>\n",
       "      <td>chr1</td>\n",
       "      <td>153371013</td>\n",
       "      <td>153375013</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  chrom      start        end  anchor\n",
       "0       22021  chr12   54686154   54690154     1.0\n",
       "1        9664   chr5   32470089   32474089     1.0\n",
       "2       11985   chr6   42035500   42039500     1.0\n",
       "3       28325  chr17   62933100   62937100     1.0\n",
       "4        1887   chr1  153371013  153375013     1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "genome = pickle.load(open(data_dir+\"hg38-003.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GGGACTACAGGTGCCCACTACCACGCCTGGCTAATTTTTTGTATTTTCAGTAGAGACGGGGTTTCACTGTGTTAGCCAGGATGGTCTCGATCTCCTGACCTCGTGATCCGCCCACCTCAGCCTCCCAAAGTGCTAGGATTACAGGTGTTAGCCACCGTGCCCAGCTAGTTTCTTTTCTTTTCTTTTTTTTTTTTTGAGCCGGAGTCTCACTCTGTCTCCCAGGCCAGAGTACAGTAGCGCGATCTCGGCTCACTGCAACCTCCACCTCCAGGGTTCAAGCAATTCTCCTGCCTCAGCCTCCCAAGTAGCTGGGATTACAGACACCCGCCACAACGCCTGGCTAATTTTTGTATTTTTAGTAGAGACGGGGTTTCACCATTTTGGCCAGGCTGGTTTTGAACTCCTGACTTTGTGATCCCCCCACCTCGGCCTCCCAAAGTGCTGGGATTATAGGTGTGAGCCATCACTCCCGGCCTAAAAATTATTATTATTATTTTGGGTTTTTTTTGAGACAGAGTCTTGCTCTGTCACCCAGGCTGGAGTGCATTGGCCCAATGTTAGCTTGCTGCGCAACCTCTGCCTCTCGGGTTCAAGCGATTCTGCTGCCTCCACCTCCCAAGTAGTTGGGATTATAGGCATGTGCCATCATGCCCAGCTAATTCTTGTATTTTCAGTAGACATGTGGTTTCACCATGTTGGCCAGGCTAGTCCTGAACTCCTGACCTCAAGTGATCCATCTGCCTCGGCCTCCCAAAGTGCTGGGATTACAGGTGTGAGCCACCATGCCTGGCCTAAAAATTATTATTTATATATATATATATATAAAATATATATATGGAGCCTTGCTCTTGTTGCCCAGGCTGGAGTGCATATATACTATATATATATATATATATATATATATTTTTTTTTTTTTTTTTTTTTTTTGACACAGGGTCTCCCTCTGTCACCCAGGCTGGAGTGCAGTGGCACAATCACTACTCACTGCAGCCTCCACCTCCCAGGTTCAAGCAATCCTCCCACCTCAGCCTCCTCCTGGTCTACAGGCGCACACCACCAAGCCTGGCTAAGTTTTGGGTCTTTTGTAGAGACAAAATTTTGCCATGTTGTCTAGGCTGGTCTCCAACTCCTGGGCTCAAGTTATCTGCCCGCCTTGGCCTCCCAAAGTGCTGAGATTACAGGCATGAGCCACTGTGCCTGGCCAGTCCTCTCTTTTCTAATGAGATACCTGCCTGAGGCCAAATTTTCTTCATATACATCAATGAAAACATATTGCAACAGATTAAATCAGAAACTGATGAAAATCCAGCTGTCTTCTATGAAGTCAGGCATTAACGAGATTTGCAAAAATGTAAAACAAGGCTATACTTCTCATTATTTTTGTTTTGGAAAATAGTTTTCATTTAAAAAAATACAATGCTTATGGATTTTTTGTTTTGTTTTGTTTTGTTTTTTTGAGACAGACTCTTGCTCTGTCACCCAGGCTGGAATGCAGTGGCGTGATCTCAGCTCACTGCAAGCTCCGCCTCTCGGGTTCACGCCATTCTCCTGCCTCAGCCTCCCGAGTAGCTGGGACTAAAGGTGCCCGCCACCACACCTGGCTAATTTTTCTGTATTTTTCAGTAGAGACAGGGTTTCACTGTGTTAGCCAGGATGGTCTCGATCTCCTGACCTCGTGATCCACCCGCCTTGGCCTCCCAAAGTGTTGGGATTACAGGCGTGAGCCACTGTGCCCGGCCGTTTTGTTTTTTTTTTTAAGACGGAGTCTCGCTTTGCCACCAGGCTGGAGTGCAGTGGCACGATCTCGGCTCACTGCAACCTCTGACTCCCTGGTTCAAGCGATTCTCCTGCCTCAGCCTCCCAAGTAGCTGGGACTACAGGCATGCACGACCATGCCCAGCTAATTTTTGTATTTTTAGTAGAGACGGTTTTCAACATATTGGCCAGGATGGTCTCAATCTCTCGACCTTGTGATCCGCCCGCCTCGGCCTCCCAAAGTGCTGGGATTACAGGCGTGAGCCACCGCGCCTGGCCAAAAAAAAATTACAATGCTTATGTTAACATGCAATGAGTTTCTTATTGTTACTTTAAATAAATTAATATTTAAAATTTCTCATATCAAATTTTTTATCAGAAACAAAATAACAACAGGTATAGGGAGGGACAAGTCAAAAGCTTATATTATTTATTCCAGGGAATGCCATGTCGGGTGCACCGATTATTAGGTATAGCCTAAAAAACAAAAGTTCTGGCCAGGCATAGTGGCATGCGCCTGTAATCACAGCACTTTGGGAGGCCGAGGCGGACGGATCATGAGGTCAGGAGTTCAAGACTAGTCTGACCAAAATGGTGAAACCCTGTCTCTAATAAAAATACAAAAATTAGCTGGGTGTGGTCGCACATGCCTGTAATCCCAGCTACTCAGGAGGCTGAGGCACGAGAATCGCTTGAACCCGGGAGGCGGAGGTTGCAGTGAGCCGAGATTGCGCCATTGCACTCCACCCTGGGCGACAGAGTGAGACTCGGTCTCAAAAAAAAAAAAAAAAAAAAGTTCTTTGGGATCCTCAATAATTTTTCAGAATGTAAAGTGGTCCTGAGATCAGAAGGCTTAAAAATTGCTGCAGCAGACCTAATATGTCAGTCTCTAAAATGCCCAATTCCAAGCCTGGTTATCTAGTTCTTGGTATTCTTTACCCTTATTCACATTTTTACCTCTTGGCCCCATTGTGCTGCTGGATTTTTTTTAACTATATTAGGGCAGGGTGCAGTGGCTCACATCTGTAATACCAGCACTTTGGGTGGCCAAGGTGGGCAGATCGCTTGAGCCCAGGAGTTCAAGACCAGCCTGCGCAACATGGCAAAACCCTGTCTCCACCAAAAATACAAAAAATTAACTGGGCGTGGTGGCTTGTGCCTGTGGTCCCAGTTACTTGGGAGGTTGAGGCAGGAGAACTGCTTGAGCCCAGGAGGCAGGAGCTGCAGTGAGCTGAGACTGTGCCACTACACTCTAGCCTGGGTGACAGAGTGAGACCCCATCTCAACTAAAAAAAAAAAAAAGCAAGAAGAGGGCATATCAAAAATAATCATTGTTCTACAAATAATAGTGATTATAGAAATAACCACTAGTTCTTTTAGAAATAAGAAATAATCAGTAATACTATAGAAAAAGAATAAGAAATAAGCCTAATAATTGCCATAGAAATAACATAAAAATTATTTCTATAATATGGCCTTCAGTAAAAAACTCAGAACATTCAGAAGAGTAAAAAGACCCAAAAGCAACCACCATTTAAAACTGCTCCGGAATAATTTCTCATCTAATCCATTCTTCTTTTATCTCCTCAAATGGCACCTTTGAGAAGAAATTCCTGGTTAACCCATGCAAAAGCAACCACTCCTTCCTCCAGATTCCCACAGCATTGTAGTTGAAACCTTTCTTGAGGCCCAGCTAGACCATAAAAGTATGCATACTGAATTCCTAAATGTGCATATTTAACGGTCATAAATTCAGTTATATCTACTGGAAGAGACACCAACCAACCACAGAAACCTATGTACTATTTATATGATGTGATCCCTTCACCCAGGCTTAACATAATGCTTAACCAAAGACCAGAGCCTGTGTTCCAACAAAAACTGGCCATGCTGAGGAATCTTAGAAATGGAAGAGAATGTCCAAATCATGTATCCTGTGTTTTATGAGCAGTCTCTTTAAAATAGAGACTTTAATAGTAACTTTGATGTGTGTCTTGTTTTTACACTGACTTTGAACCCAACACTGTGTCAAATGTGGCTCCACTACATGAAGAATGGACAAGTGAATGGTTCCAAGGCCTCTGAGACTTACAGATGTTGGATGAATATACTAGGTGACTGAGCCCAGGAGTCCTCGACCCATGTAGTCCTGTCCTCTGGACAGGGTATGTGGCATCCCCTCTAGGCCAGGGCTGCCACCCATTGCTGGGTGAAGGTCTCAGGTGTCACTTGAAGGCCAAGGTGA'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome[\"chr6\"][42035500:42039500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133797422"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genome[\"chr10\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt=0\n",
    "\n",
    "context_length = 4000\n",
    "for i,row in enumerate(val_data.itertuples()):\n",
    "    midpoint = int(.5 * (row.start + row.end))\n",
    "    seq = genome[row.chrom][midpoint - context_length//2:midpoint + context_length//2]\n",
    "    if(np.isnan(row.anchor)):\n",
    "        cnt += 1\n",
    "    else:\n",
    "        pass\n",
    "#         seq2 = genome[row.chrom][row.start:row.end]\n",
    "#         print(len(seq),len(seq2), row.anchor, len(genome[row.chrom]))\n",
    "cnt/len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AnchorDataset(torch.utils.data.IterableDataset):\n",
    "\n",
    "#     def __init__(self, anchor_data, genome, rnn_length):\n",
    "#         super().__init__()\n",
    "#         self.rnn_len = rnn_length\n",
    "#         self.anchor_data = anchor_data\n",
    "#         self.genome = genome\n",
    "#         self.context_len = 4000\n",
    "        \n",
    "#     def __iter__(self): \n",
    "#         for i,row in enumerate(self.anchor_data.itertuples()):\n",
    "#             lab = row.anchor\n",
    "#             midpoint = int(.5 * (row.start + row.end))\n",
    "#             seq = self.genome[row.chrom][ midpoint - self.context_len//2:midpoint + self.context_len//2]\n",
    "#             if len(seq) < self.context_len:\n",
    "#                 continue\n",
    "            \n",
    "#             oh_cnn_seq = one_hot(seq).transpose() # 4k, 5\n",
    "#             #for rnn\n",
    "#             rnn_start = int(self.context_len / 2 - self.rnn_len / 2)\n",
    "#             rnn_end = int(self.context_len / 2 + self.rnn_len / 2)\n",
    "#             rnn_seq = seq[rnn_start: rnn_end]\n",
    "#             oh_rnn_seq = one_hot(rnn_seq).transpose()\n",
    "            \n",
    "#             yield(oh_cnn_seq, oh_rnn_seq, np.float32(lab))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnchorDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, anchor_data, genome, rnn_length):\n",
    "        super().__init__()\n",
    "        self.rnn_len = rnn_length\n",
    "        self.anchor_data = anchor_data\n",
    "        self.genome = genome\n",
    "        self.context_len = 4000\n",
    "        self.processed_data = []\n",
    "        \n",
    "        print('Preparing a dataset...')\n",
    "        for i,row in tqdm.tqdm(enumerate(self.anchor_data.itertuples()), total=len(anchor_data)):\n",
    "            lab = row.anchor\n",
    "            midpoint = int(.5 * (row.start + row.end))\n",
    "            seq = self.genome[row.chrom][ midpoint - self.context_len//2:midpoint + self.context_len//2]\n",
    "            if len(seq) < self.context_len or np.isnan(row.anchor):\n",
    "                continue\n",
    "            \n",
    "            oh_cnn_seq = one_hot(seq).transpose() # 4k, 5\n",
    "            #for rnn\n",
    "            rnn_start = int(self.context_len / 2 - self.rnn_len / 2)\n",
    "            rnn_end = int(self.context_len / 2 + self.rnn_len / 2)\n",
    "            rnn_seq = seq[rnn_start: rnn_end]\n",
    "            oh_rnn_seq = one_hot(rnn_seq).transpose()\n",
    "            self.processed_data.append((oh_cnn_seq, oh_rnn_seq, np.float32(lab)))\n",
    "        \n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.processed_data)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        return self.processed_data[idx]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Anchor_LSTM_Model(nn.Module):\n",
    "    def __init__(self, in_dim=5, hid_dim=128, out_dim=1):\n",
    "        super().__init__()\n",
    "        self.lstm1 = nn.LSTM(in_dim, hid_dim, batch_first=True, bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(hid_dim * 2, hid_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hid_dim * 2, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        return self.fc(x).view(batch_size, -1)\n",
    "\n",
    "    \n",
    "class Anchor_CNN_Model(nn.Module):\n",
    "    def __init__(self, layer1_out=256, layer2_out=512, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.seq_len = 4000\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels=1, out_channels=layer1_out, kernel_size=(17,5)),\n",
    "                        nn.BatchNorm2d(layer1_out),\n",
    "                        nn.LeakyReLU(0.2),\n",
    "                        nn.Dropout2d(dropout),\n",
    "                    )\n",
    "        \n",
    "        #dilated conv dilation=1\n",
    "        self.layer2_1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels=layer1_out, out_channels=layer2_out, kernel_size=(5,1), dilation=1, padding='same'),\n",
    "                        nn.BatchNorm2d(layer2_out),\n",
    "                        nn.LeakyReLU(0.2),\n",
    "                        nn.MaxPool2d(kernel_size=(self.seq_len - 16, 1), stride=(self.seq_len - 16, 1)),\n",
    "                        nn.Dropout2d(dropout),\n",
    "                    )\n",
    "        \n",
    "        #dilated conv dilation=3\n",
    "        self.layer2_2 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels=layer1_out, out_channels=layer2_out, kernel_size=(5,1), dilation=3, padding='same'),\n",
    "                        nn.BatchNorm2d(layer2_out),\n",
    "                        nn.LeakyReLU(0.2),\n",
    "                        nn.MaxPool2d(kernel_size=(self.seq_len - 16, 1), stride=(self.seq_len - 16, 1)),\n",
    "                        nn.Dropout2d(dropout),\n",
    "                    )\n",
    "        \n",
    "        #dilated conv dilation=7\n",
    "        self.layer2_3 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels=layer1_out, out_channels=layer2_out, kernel_size=(5,1), dilation=7, padding='same'),\n",
    "                        nn.BatchNorm2d(layer2_out),\n",
    "                        nn.LeakyReLU(0.2),\n",
    "                        nn.MaxPool2d(kernel_size=(self.seq_len - 16, 1), stride=(self.seq_len - 16, 1)),\n",
    "                        nn.Dropout2d(dropout),\n",
    "                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1) #[*, 1, 4k, 5]\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.layer1(x)\n",
    "        o1 = self.layer2_1(x).view(batch_size, -1)\n",
    "        o2 = self.layer2_2(x).view(batch_size, -1)\n",
    "        o3 = self.layer2_3(x).view(batch_size, -1)\n",
    "        out = torch.cat((o1,o2,o3), -1)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "class Anchor_CNN_LSTM(nn.Module):\n",
    "    def __init__(self,\n",
    "                 use_lstm=True,\n",
    "                 use_cnn=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        out_dim = 0\n",
    "        \n",
    "        if use_lstm == True:\n",
    "            self.lstm_model = Anchor_LSTM_Model()\n",
    "            out_dim += 800\n",
    "            \n",
    "        if use_cnn == True:\n",
    "            self.cnn_model = Anchor_CNN_Model()\n",
    "            out_dim += 1536\n",
    "        \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "                            nn.Linear(out_dim, 512),\n",
    "                            nn.BatchNorm1d(512),\n",
    "                            nn.LeakyReLU(0.2),\n",
    "                            nn.Dropout(0.2),\n",
    "            \n",
    "                            nn.Linear(512, 256),\n",
    "                            nn.BatchNorm1d(256),\n",
    "                            nn.LeakyReLU(0.2),\n",
    "                            nn.Dropout(0.2),\n",
    "                            \n",
    "                            nn.Linear(256, 1),\n",
    "                            nn.Sigmoid()\n",
    "                        )\n",
    "\n",
    "    def forward(self, x_cnn, x_rnn):\n",
    "        x2 = self.cnn_model(x_cnn)\n",
    "        x1 = self.lstm_model(x_rnn)\n",
    "\n",
    "        x = torch.cat((x2, x1), -1)\n",
    "\n",
    "        out = self.classifier(x)\n",
    "\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 64\n",
    "# train_dataset = AnchorDataset(train_data, genome, 800)\n",
    "# train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers = 0) 72302\n",
    "\n",
    "# val_dataset = AnchorDataset(val_data, genome, 800)\n",
    "# val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers = 0) 1600\n",
    "\n",
    "# test_dataset = AnchorDataset(test_data, genome, 800)\n",
    "# test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers = 0) 5670\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_epoch(train_flag, dataloader, cnn_1d, optimizer, device, dataset_size, epoch):\n",
    "\n",
    "    torch.set_grad_enabled(train_flag)\n",
    "    cnn_1d.train() if train_flag else cnn_1d.eval() \n",
    "\n",
    "    losses = []\n",
    "#     accuracies = []\n",
    "#     auprcs = []\n",
    "    \n",
    "    all_ys = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with tqdm.tqdm(enumerate(dataloader), total=(dataset_size), unit=\"batch\") as tepoch:\n",
    "        for idx, (x_cnn, x_rnn, y) in tepoch: #tqdm.tqdm(enumerate(dataloader), total=dataset_size): # collection of tuples with iterator\n",
    "            tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "            (x_cnn, x_rnn, y) = ( x_cnn.to(device), x_rnn.to(device), y.to(device) ) # transfer data to GPU\n",
    "\n",
    "            output = cnn_1d(x_cnn, x_rnn) # forward pass\n",
    "            output = output.squeeze() # remove spurious channel dimension\n",
    "            loss = F.binary_cross_entropy( output, y ) # numerically stable\n",
    "\n",
    "            if train_flag: \n",
    "                loss.backward() # back propagation\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            losses.append(loss.detach().cpu().numpy())\n",
    "            accuracy = torch.mean( ( (output > .5) == (y > .5) ).float() )\n",
    "#             print('idx',idx, loss.item(), y, output)\n",
    "\n",
    "            y_np = y.detach().cpu().numpy()\n",
    "            probs_np = output.detach().cpu().numpy()\n",
    "        \n",
    "#             auprc = sklearn.metrics.average_precision_score(y_np, probs_np)\n",
    "#             auprcs.append(auprc)\n",
    "#             accuracies.append(accuracy.detach().cpu().numpy())\n",
    "            \n",
    "            all_ys.extend(y_np.tolist())\n",
    "            all_probs.extend(probs_np.tolist())\n",
    "            \n",
    "            tepoch.set_postfix(loss=loss.item(), batch_accuracy=100. * accuracy.detach().cpu().numpy())#, batch_auprc=100. * auprc)\n",
    "            \n",
    "    all_ys = np.array(all_ys)\n",
    "    all_probs = np.array(all_probs)\n",
    "    precision, recall, thresholds = sklearn.metrics.precision_recall_curve(all_ys, all_probs)\n",
    "    epoch_acc = np.mean( ( (all_probs > .5) == (all_ys > .5) ) )\n",
    "    \n",
    "    return( np.mean(losses), epoch_acc, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(cnn_1d, train_data, validation_data, epochs=15, patience=4, verbose = True):\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    cnn_1d = cnn_1d.to(device)\n",
    "\n",
    "    batch_size = 64\n",
    "    train_dataset = AnchorDataset(train_data, genome, 800)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers = 0, shuffle=True)\n",
    "    \n",
    "    val_dataset = AnchorDataset(val_data, genome, 800)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers = 0)\n",
    "\n",
    "    optimizer = torch.optim.RMSprop(cnn_1d.parameters())\n",
    "    \n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    patience_counter = patience\n",
    "    best_val_loss = np.inf\n",
    "    check_point_filename = 'anchor_model_checkpoint.pt' # to save the best model fit to date\n",
    "    for epoch in range(epochs):\n",
    "        start_time = timeit.default_timer()\n",
    "        \n",
    "        train_loss, train_acc, train_pr, train_rec = run_one_epoch(True, train_dataloader, cnn_1d, optimizer, device, math.ceil(len(train_dataset)/batch_size), epoch)\n",
    "        val_loss, val_acc, val_pr, val_rec = run_one_epoch(False, val_dataloader, cnn_1d, optimizer, device, math.ceil(len(val_dataset)/batch_size), epoch)\n",
    "        \n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        if val_loss < best_val_loss: \n",
    "            torch.save(cnn_1d.state_dict(), check_point_filename)\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = patience\n",
    "        else: \n",
    "            patience_counter -= 1\n",
    "            if patience_counter <= 0: \n",
    "                cnn_1d.load_state_dict(torch.load(check_point_filename)) # recover the best model so far\n",
    "                break\n",
    "        elapsed = float(timeit.default_timer() - start_time)\n",
    "        \n",
    "        if verbose == True:\n",
    "            train_auprc = sklearn.metrics.auc(train_rec, train_pr)\n",
    "            val_auprc = sklearn.metrics.auc(val_rec, val_pr)\n",
    "            print(\"Epoch %i took %.2fs. Train loss: %.4f acc: %.4f. auprc: %.4f. Val loss: %.4f acc: %.4f. auprc: %.4f. Patience left: %i\" % \n",
    "                  (epoch+1, elapsed, train_loss, train_acc, train_auprc, val_loss, val_acc, val_auprc, patience_counter ))\n",
    "    \n",
    "    return cnn_1d, train_accs, val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 169/72500 [00:00<00:43, 1680.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing a dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72500/72500 [00:43<00:00, 1685.87it/s] \n",
      "  8%|▊         | 120/1600 [00:00<00:01, 1199.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing a dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1600/1600 [00:01<00:00, 1250.28it/s]\n",
      "Epoch 0: 100%|██████████| 904/904 [15:59<00:00,  1.06s/batch, batch_accuracy=80, loss=0.406]  \n",
      "Epoch 0: 100%|██████████| 22/22 [00:09<00:00,  2.44batch/s, batch_accuracy=98.2, loss=0.238]\n",
      "Epoch 1:   0%|          | 0/904 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 took 968.75s. Train loss: 0.5061 acc: 0.7577. auprc: 0.8383. Val loss: 0.4183 acc: 0.8064. auprc: 0.9493. Patience left: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 904/904 [15:59<00:00,  1.06s/batch, batch_accuracy=80, loss=0.195]  \n",
      "Epoch 1: 100%|██████████| 22/22 [00:09<00:00,  2.43batch/s, batch_accuracy=100, loss=0.00846]\n",
      "Epoch 2:   0%|          | 0/904 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 took 968.58s. Train loss: 0.3959 acc: 0.8216. auprc: 0.9034. Val loss: 0.9885 acc: 0.5643. auprc: 0.9534. Patience left: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 904/904 [15:59<00:00,  1.06s/batch, batch_accuracy=80, loss=0.306]  \n",
      "Epoch 2: 100%|██████████| 22/22 [00:09<00:00,  2.44batch/s, batch_accuracy=85.7, loss=0.331]\n",
      "Epoch 3:   0%|          | 0/904 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 took 968.81s. Train loss: 0.3668 acc: 0.8364. auprc: 0.9180. Val loss: 0.4158 acc: 0.8214. auprc: 0.9465. Patience left: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 904/904 [15:59<00:00,  1.06s/batch, batch_accuracy=90, loss=0.285]  \n",
      "Epoch 3: 100%|██████████| 22/22 [00:09<00:00,  2.43batch/s, batch_accuracy=100, loss=0.0194]\n",
      "Epoch 4:   0%|          | 0/904 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 took 968.82s. Train loss: 0.3536 acc: 0.8419. auprc: 0.9238. Val loss: 0.7629 acc: 0.6443. auprc: 0.9583. Patience left: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 904/904 [15:58<00:00,  1.06s/batch, batch_accuracy=100, loss=0.12]  \n",
      "Epoch 4: 100%|██████████| 22/22 [00:09<00:00,  2.43batch/s, batch_accuracy=100, loss=0.0515] \n",
      "Epoch 5:   0%|          | 0/904 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 took 967.31s. Train loss: 0.3365 acc: 0.8495. auprc: 0.9312. Val loss: 0.3613 acc: 0.8193. auprc: 0.9682. Patience left: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 904/904 [16:00<00:00,  1.06s/batch, batch_accuracy=80, loss=0.941]  \n",
      "Epoch 5: 100%|██████████| 22/22 [00:09<00:00,  2.44batch/s, batch_accuracy=85.7, loss=0.333]\n",
      "Epoch 6:   0%|          | 0/904 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 took 969.84s. Train loss: 0.3215 acc: 0.8568. auprc: 0.9379. Val loss: 0.3455 acc: 0.8493. auprc: 0.9583. Patience left: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 904/904 [16:00<00:00,  1.06s/batch, batch_accuracy=90, loss=0.252]  \n",
      "Epoch 6: 100%|██████████| 22/22 [00:09<00:00,  2.43batch/s, batch_accuracy=30.4, loss=1.07] \n",
      "Epoch 7:   0%|          | 0/904 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 took 969.06s. Train loss: 0.3052 acc: 0.8661. auprc: 0.9439. Val loss: 0.4522 acc: 0.7764. auprc: 0.9546. Patience left: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 904/904 [15:59<00:00,  1.06s/batch, batch_accuracy=80, loss=0.437]  \n",
      "Epoch 7: 100%|██████████| 22/22 [00:09<00:00,  2.43batch/s, batch_accuracy=94.6, loss=0.169]\n",
      "Epoch 8:   0%|          | 0/904 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 took 968.80s. Train loss: 0.2866 acc: 0.8749. auprc: 0.9512. Val loss: 0.3553 acc: 0.8386. auprc: 0.9603. Patience left: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 904/904 [15:59<00:00,  1.06s/batch, batch_accuracy=70, loss=1.06]   \n",
      "Epoch 8: 100%|██████████| 22/22 [00:09<00:00,  2.43batch/s, batch_accuracy=100, loss=0.00194]\n",
      "Epoch 9:   0%|          | 0/904 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 took 968.93s. Train loss: 0.2730 acc: 0.8808. auprc: 0.9561. Val loss: 0.8098 acc: 0.6886. auprc: 0.9672. Patience left: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 904/904 [15:59<00:00,  1.06s/batch, batch_accuracy=80, loss=0.805]  \n",
      "Epoch 9: 100%|██████████| 22/22 [00:09<00:00,  2.44batch/s, batch_accuracy=98.2, loss=0.086]\n"
     ]
    }
   ],
   "source": [
    "my_cnn1d = Anchor_CNN_LSTM()\n",
    "my_cnn1d, train_accs, val_accs = train_model(my_cnn1d, train_data, val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    batch_size = 64\n",
    "    test_dataset = AnchorDataset(test_data, genome, 800)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers = 0)\n",
    "    test_loss, test_acc, test_pr, test_rec = run_one_epoch(False, \n",
    "                                                   test_dataloader, \n",
    "                                                   model, \n",
    "                                                   None, \n",
    "                                                   device, \n",
    "                                                   math.ceil(len(test_dataset)/batch_size), \n",
    "                                                   0)\n",
    "    test_auprc = sklearn.metrics.auc(test_rec, test_pr)\n",
    "    return test_pr, test_rec, test_auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 328/5700 [00:00<00:03, 1618.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing a dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5700/5700 [00:02<00:00, 1971.31it/s]\n",
      "Epoch 0: 100%|██████████| 75/75 [00:30<00:00,  2.45batch/s, batch_accuracy=85.3, loss=0.405] \n"
     ]
    }
   ],
   "source": [
    "test_pr, test_rec, test_auprc = test_model(my_cnn1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9489202174230047"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test_rec, test_pr, color=\"red\", linestyle='--', label=f'CNN + LSTM (0.948)')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Anchor_CNN_LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(dummy3, dummy).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=Anchor_LSTM_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = torch.rand((10, 800, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = m(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 800])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2=Anchor_CNN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy3=torch.rand((10,4000,5))\n",
    "# b2=m2(dummy3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1536])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2336])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy4=torch.cat((b2,b1), -1)\n",
    "dummy4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nn.Sequential(\n",
    "                            nn.Linear(5536, 512),\n",
    "                            nn.BatchNorm1d(512),\n",
    "                            nn.LeakyReLU(0.2),\n",
    "                            nn.Dropout(0.2),\n",
    "            \n",
    "                            nn.Linear(512, 256),\n",
    "                            nn.BatchNorm1d(256),\n",
    "                            nn.LeakyReLU(0.2),\n",
    "                            nn.Dropout(0.2),\n",
    "                            \n",
    "                            nn.Linear(256, 1),\n",
    "                            nn.Sigmoid()\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-4724d8f72c8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "classifier(dummy4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 4000, 5])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy2=torch.rand((10, 1, 4000, 5))\n",
    "dummy2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_out=256\n",
    "layer2_out=512\n",
    "dropout=0.2\n",
    "layer1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels=1, out_channels=layer1_out, kernel_size=(17,5)),\n",
    "                        nn.BatchNorm2d(layer1_out),\n",
    "                        nn.LeakyReLU(0.2),\n",
    "                        nn.Dropout2d(dropout),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 4000, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256, 3984, 1])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dummy2.shape)\n",
    "o1=layer1(dummy2)\n",
    "o1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2_1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels=layer1_out, out_channels=layer2_out, kernel_size=(5,1), dilation=1, padding='same'),\n",
    "                        nn.BatchNorm2d(layer2_out),\n",
    "                        nn.LeakyReLU(0.2),\n",
    "                        nn.MaxPool2d(kernel_size=(4000 - 16, 1), stride=(4000 - 16, 1)),\n",
    "                        nn.Dropout2d(dropout),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256, 3984, 1])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy3=torch.rand((10, 256, 3984, 1))\n",
    "ll=nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(5,1), dilation=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512, 1, 1])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2_1(o1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
